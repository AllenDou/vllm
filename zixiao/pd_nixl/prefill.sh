CUDA_VISIBLE_DEVICES=0 VLLM_NIXL_SIDE_CHANNEL_PORT=5559 /usr/bin/python3 /usr/local/bin/vllm serve /nasmnt/Llama-3.2-1B-Instruct/ --enforce-eager --host 0.0.0.0 --port 8100 --tensor-parallel-size 1 --seed 1024 --dtype float16 --max-model-len 200 --max-num-batched-tokens 200 --max-num-seqs 32 --trust-remote-code --gpu-memory-utilization 0.8 --disable-log-request --disable-log-stats --kv-transfer-config "{\"kv_connector\":\"NixlConnector\",\"kv_role\":\"kv_both\"}"

